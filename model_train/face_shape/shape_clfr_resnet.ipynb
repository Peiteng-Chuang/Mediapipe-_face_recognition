{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import layers, regularizers,models, callbacks, optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import cv2  \n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "path_0 = './0_round'\n",
    "path_1 = './1_square'\n",
    "path_2 = './2_heart'\n",
    "path_3 = './3_long'\n",
    "path_4 = './4_oval'\n",
    "path_5 = './5_triangle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(241, 150, 150, 3)\n",
      "(61, 150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "# 清除当前会话中的模型\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "features, labels = [], []\n",
    "\n",
    "# 定义一个函数来读取图像并添加到features和labels\n",
    "def read_images_from_path(path, label):\n",
    "    for file_name in os.listdir(path):\n",
    "        if file_name.endswith('.jpg'):\n",
    "            img_path = os.path.join(path, file_name)\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_COLOR)  # 读取彩色图像\n",
    "            if img is not None:\n",
    "                img = cv2.resize(img, (150, 150))\n",
    "                features.append(img)\n",
    "                labels.append(label)\n",
    "\n",
    "# 读取所有类别的图像\n",
    "read_images_from_path(path_0, 0)\n",
    "read_images_from_path(path_1, 1)\n",
    "read_images_from_path(path_2, 2)\n",
    "read_images_from_path(path_3, 3)\n",
    "read_images_from_path(path_4, 4)\n",
    "read_images_from_path(path_5, 5)\n",
    "\n",
    "# 转换列表为numpy数组并归一化图像\n",
    "features = np.asarray(features, np.float32) / 255.0\n",
    "labels = np.asarray(labels, np.int32)\n",
    "\n",
    "# 重新调整图像的形状以匹配神经网络的输入形状 (4D)\n",
    "train_images = features.reshape((-1, 150, 150, 3))  # 彩色图像有3个通道\n",
    "train_labels = labels\n",
    "\n",
    "# 分割训练集和验证集\n",
    "x_train, x_val, y_train, y_val = train_test_split(train_images, train_labels, test_size=0.2, random_state=6)\n",
    "\n",
    "# 将标签转换为one-hot编码\n",
    "y_train = to_categorical(y_train, num_classes=6)\n",
    "y_val = to_categorical(y_val, num_classes=6)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 150, 150, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 156, 156, 3)  0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 75, 75, 64)   9472        ['conv1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 75, 75, 64)   256         ['conv1_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 75, 75, 64)   0           ['conv1_bn[0][0]']               \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 77, 77, 64)   0           ['conv1_relu[0][0]']             \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 38, 38, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 38, 38, 64)   4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 38, 38, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 38, 38, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 38, 38, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 38, 38, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 38, 38, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 38, 38, 256)  16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 38, 38, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 38, 38, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 38, 38, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 38, 38, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 38, 38, 256)  0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 38, 38, 64)   16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 38, 38, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 38, 38, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 38, 38, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 38, 38, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 38, 38, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 38, 38, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 38, 38, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 38, 38, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 38, 38, 256)  0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 38, 38, 64)   16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 38, 38, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 38, 38, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 38, 38, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 38, 38, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 38, 38, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 38, 38, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 38, 38, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 38, 38, 256)  0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 38, 38, 256)  0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 19, 19, 128)  32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 19, 19, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 19, 19, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 19, 19, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 19, 19, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 19, 19, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 19, 19, 512)  131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 19, 19, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 19, 19, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 19, 19, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 19, 19, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 19, 19, 512)  0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 19, 19, 128)  65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 19, 19, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 19, 19, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 19, 19, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 19, 19, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 19, 19, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 19, 19, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 19, 19, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 19, 19, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 19, 19, 512)  0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 19, 19, 128)  65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 19, 19, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 19, 19, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 19, 19, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 19, 19, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 19, 19, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 19, 19, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 19, 19, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 19, 19, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 19, 19, 512)  0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 19, 19, 128)  65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 19, 19, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 19, 19, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 19, 19, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 19, 19, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 19, 19, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 19, 19, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 19, 19, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 19, 19, 512)  0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 19, 19, 512)  0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 10, 10, 256)  131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 10, 10, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 10, 10, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 10, 10, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 10, 10, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 10, 10, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 10, 10, 1024  525312      ['conv3_block4_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 10, 10, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 10, 10, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 10, 10, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 10, 10, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 10, 10, 1024  0           ['conv4_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 10, 10, 256)  262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 10, 10, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 10, 10, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 10, 10, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 10, 10, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 10, 10, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 10, 10, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 10, 10, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 10, 10, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 10, 10, 1024  0           ['conv4_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 10, 10, 256)  262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 10, 10, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 10, 10, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 10, 10, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 10, 10, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 10, 10, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 10, 10, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 10, 10, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 10, 10, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 10, 10, 1024  0           ['conv4_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 10, 10, 256)  262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 10, 10, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 10, 10, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 10, 10, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 10, 10, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 10, 10, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 10, 10, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 10, 10, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 10, 10, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 10, 10, 1024  0           ['conv4_block4_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 10, 10, 256)  262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 10, 10, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 10, 10, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 10, 10, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 10, 10, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 10, 10, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 10, 10, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 10, 10, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 10, 10, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 10, 10, 1024  0           ['conv4_block5_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 10, 10, 256)  262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 10, 10, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 10, 10, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 10, 10, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 10, 10, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 10, 10, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 10, 10, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 10, 10, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 10, 10, 1024  0           ['conv4_block5_out[0][0]',       \n",
      "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 10, 10, 1024  0           ['conv4_block6_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 5, 5, 512)    524800      ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 5, 5, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 5, 5, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 5, 5, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 5, 5, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 5, 5, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 5, 5, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 5, 5, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 5, 5, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_3_bn (BatchNormal  (None, 5, 5, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_add (Add)         (None, 5, 5, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
      "                                                                  'conv5_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block1_out (Activation)  (None, 5, 5, 2048)   0           ['conv5_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 5, 5, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 5, 5, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 5, 5, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 5, 5, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 5, 5, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 5, 5, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 5, 5, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_3_bn (BatchNormal  (None, 5, 5, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_add (Add)         (None, 5, 5, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block2_out (Activation)  (None, 5, 5, 2048)   0           ['conv5_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 5, 5, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 5, 5, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 5, 5, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 5, 5, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 5, 5, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 5, 5, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 5, 5, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_3_bn (BatchNormal  (None, 5, 5, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_add (Add)         (None, 5, 5, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv5_block3_out (Activation)  (None, 5, 5, 2048)   0           ['conv5_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1024)         2098176     ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1024)         0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 256)          262400      ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 256)          0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 6)            1542        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 25,949,830\n",
      "Trainable params: 2,362,118\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 6s 553ms/step - loss: 2.1585 - accuracy: 0.1577 - val_loss: 1.7162 - val_accuracy: 0.3443 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 4s 472ms/step - loss: 1.9730 - accuracy: 0.1992 - val_loss: 1.7117 - val_accuracy: 0.3443 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 4s 469ms/step - loss: 1.9503 - accuracy: 0.2490 - val_loss: 1.6979 - val_accuracy: 0.3443 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 4s 474ms/step - loss: 1.8508 - accuracy: 0.2780 - val_loss: 1.6901 - val_accuracy: 0.3443 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 4s 476ms/step - loss: 1.8636 - accuracy: 0.2573 - val_loss: 1.6883 - val_accuracy: 0.3443 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 4s 471ms/step - loss: 1.9243 - accuracy: 0.1784 - val_loss: 1.6870 - val_accuracy: 0.3443 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 4s 473ms/step - loss: 1.9165 - accuracy: 0.2407 - val_loss: 1.6871 - val_accuracy: 0.3443 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 4s 463ms/step - loss: 1.8688 - accuracy: 0.2407 - val_loss: 1.6882 - val_accuracy: 0.3443 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 4s 469ms/step - loss: 1.8642 - accuracy: 0.2614 - val_loss: 1.6892 - val_accuracy: 0.3443 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 4s 472ms/step - loss: 1.7852 - accuracy: 0.2324 - val_loss: 1.6919 - val_accuracy: 0.3443 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 4s 470ms/step - loss: 1.8290 - accuracy: 0.2116 - val_loss: 1.6935 - val_accuracy: 0.3443 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 4s 471ms/step - loss: 1.8299 - accuracy: 0.2407 - val_loss: 1.6935 - val_accuracy: 0.3443 - lr: 2.0000e-05\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 4s 495ms/step - loss: 1.7976 - accuracy: 0.2199 - val_loss: 1.6930 - val_accuracy: 0.3443 - lr: 2.0000e-05\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 4s 469ms/step - loss: 1.7620 - accuracy: 0.2407 - val_loss: 1.6928 - val_accuracy: 0.3443 - lr: 2.0000e-05\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 4s 468ms/step - loss: 1.8010 - accuracy: 0.2531 - val_loss: 1.6931 - val_accuracy: 0.3443 - lr: 2.0000e-05\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 4s 471ms/step - loss: 1.7569 - accuracy: 0.2365 - val_loss: 1.6939 - val_accuracy: 0.3443 - lr: 2.0000e-05\n",
      "Epoch 1/50\n",
      "8/8 [==============================] - 11s 1s/step - loss: 1.8554 - accuracy: 0.2199 - val_loss: 1.6859 - val_accuracy: 0.3443 - lr: 1.0000e-05\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 16s 2s/step - loss: 1.7515 - accuracy: 0.2656 - val_loss: 1.6859 - val_accuracy: 0.3443 - lr: 1.0000e-05\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 16s 2s/step - loss: 1.8254 - accuracy: 0.2116 - val_loss: 1.6869 - val_accuracy: 0.3443 - lr: 1.0000e-05\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 16s 2s/step - loss: 1.7458 - accuracy: 0.2697 - val_loss: 1.6887 - val_accuracy: 0.3443 - lr: 1.0000e-05\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 16s 2s/step - loss: 1.8055 - accuracy: 0.2697 - val_loss: 1.6907 - val_accuracy: 0.3443 - lr: 1.0000e-05\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 16s 2s/step - loss: 1.7693 - accuracy: 0.2241 - val_loss: 1.6928 - val_accuracy: 0.3443 - lr: 1.0000e-05\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 16s 2s/step - loss: 1.7499 - accuracy: 0.2531 - val_loss: 1.6939 - val_accuracy: 0.3443 - lr: 2.0000e-06\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 16s 2s/step - loss: 1.7637 - accuracy: 0.2407 - val_loss: 1.6959 - val_accuracy: 0.3443 - lr: 2.0000e-06\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 16s 2s/step - loss: 1.7492 - accuracy: 0.2697 - val_loss: 1.6990 - val_accuracy: 0.3443 - lr: 2.0000e-06\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 16s 2s/step - loss: 1.7741 - accuracy: 0.2531 - val_loss: 1.7045 - val_accuracy: 0.3443 - lr: 2.0000e-06\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 16s 2s/step - loss: 1.7537 - accuracy: 0.2448 - val_loss: 1.7126 - val_accuracy: 0.3443 - lr: 2.0000e-06\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# 清除当前会话中的模型\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 定义图像数据生成器用于数据增强\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "# 假设 x_train, y_train, x_val, y_val 已经准备好\n",
    "# 这里用 train_datagen.flow() 和 val_datagen.flow() 来生成数据\n",
    "\n",
    "# 定义一个输入层，将彩色图像输入\n",
    "input_tensor = layers.Input(shape=(150, 150, 3))  # 彩色图像有3个通道\n",
    "\n",
    "# 使用 ResNet50 作为基础模型\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
    "\n",
    "# 冻结基础模型的所有层\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# 添加自定义顶层\n",
    "x = base_model.output\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(256, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "predictions = layers.Dense(6, activation='softmax')(x)\n",
    "\n",
    "# 创建最终模型\n",
    "model = Model(inputs=input_tensor, outputs=predictions)\n",
    "\n",
    "# 查看模型层次\n",
    "model.summary()\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 设置回调函数\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)\n",
    "\n",
    "# 训练模型\n",
    "history = model.fit(\n",
    "    train_datagen.flow(x_train, y_train, batch_size=32),\n",
    "    epochs=100,\n",
    "    validation_data=val_datagen.flow(x_val, y_val),\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "# 解冻部分基础模型层，进行微调\n",
    "for layer in base_model.layers[-30:]:  # 解冻最后30层\n",
    "    layer.trainable = True\n",
    "\n",
    "# 重新编译模型（在较低学习率下微调）\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=1e-5),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 继续训练模型（微调）\n",
    "history_fine_tune = model.fit(\n",
    "    train_datagen.flow(x_train, y_train, batch_size=32),\n",
    "    epochs=50,\n",
    "    validation_data=val_datagen.flow(x_val, y_val),\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#載入舊模型\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.models import load_model\n",
    "load_model_path='C:/DL_model/best_model.h5'\n",
    "model = load_model(load_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\User\\anaconda3\\envs\\DL_39\\lib\\site-packages\\keras\\engine\\training.py\", line 2169, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\User\\anaconda3\\envs\\DL_39\\lib\\site-packages\\keras\\engine\\training.py\", line 2155, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\User\\anaconda3\\envs\\DL_39\\lib\\site-packages\\keras\\engine\\training.py\", line 2143, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\User\\anaconda3\\envs\\DL_39\\lib\\site-packages\\keras\\engine\\training.py\", line 2111, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\User\\anaconda3\\envs\\DL_39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\User\\anaconda3\\envs\\DL_39\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 280, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential' (type Sequential).\n    \n    Input 0 of layer \"conv2d\" is incompatible with the layer: expected axis -1 of input shape to have value 1, but received input with shape (None, 150, 150, 3)\n    \n    Call arguments received by layer 'sequential' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, 150, 150, 3), dtype=float32)\n      • training=False\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 34\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Iterate over each image path and plot\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, image_path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(image_paths):\n\u001b[1;32m---> 34\u001b[0m     \u001b[43mpredict_and_plot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m plt\u001b[38;5;241m.\u001b[39mtight_layout()\n\u001b[0;32m     37\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "Cell \u001b[1;32mIn[4], line 15\u001b[0m, in \u001b[0;36mpredict_and_plot\u001b[1;34m(image_path, model, ax)\u001b[0m\n\u001b[0;32m     12\u001b[0m img_resized \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_resized, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Add batch dimension\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Predict using the model\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_resized\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m class_label \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(prediction)\n\u001b[0;32m     17\u001b[0m prob_distribution \u001b[38;5;241m=\u001b[39m prediction\u001b[38;5;241m.\u001b[39msqueeze()\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\DL_39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filehhusd0sv.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\User\\anaconda3\\envs\\DL_39\\lib\\site-packages\\keras\\engine\\training.py\", line 2169, in predict_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\User\\anaconda3\\envs\\DL_39\\lib\\site-packages\\keras\\engine\\training.py\", line 2155, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\User\\anaconda3\\envs\\DL_39\\lib\\site-packages\\keras\\engine\\training.py\", line 2143, in run_step  **\n        outputs = model.predict_step(data)\n    File \"c:\\Users\\User\\anaconda3\\envs\\DL_39\\lib\\site-packages\\keras\\engine\\training.py\", line 2111, in predict_step\n        return self(x, training=False)\n    File \"c:\\Users\\User\\anaconda3\\envs\\DL_39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\User\\anaconda3\\envs\\DL_39\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 280, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential' (type Sequential).\n    \n    Input 0 of layer \"conv2d\" is incompatible with the layer: expected axis -1 of input shape to have value 1, but received input with shape (None, 150, 150, 3)\n    \n    Call arguments received by layer 'sequential' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, 150, 150, 3), dtype=float32)\n      • training=False\n      • mask=None\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x600 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'model' is your trained model\n",
    "\n",
    "# Function to predict and plot images\n",
    "def predict_and_plot(image_path, model, ax):\n",
    "    # Load and preprocess the image\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "    img_resized = cv2.resize(img, (150, 150))\n",
    "    img_resized = img_resized / 255.0\n",
    "    img_resized = np.expand_dims(img_resized, axis=0)  # Add batch dimension\n",
    "    \n",
    "    # Predict using the model\n",
    "    prediction = model.predict(img_resized)\n",
    "    class_label = np.argmax(prediction)\n",
    "    prob_distribution = prediction.squeeze()\n",
    "    prob_distribution_str = '\\n'.join([f'Class {i}: {prob:.2f}' for i, prob in enumerate(prob_distribution)])\n",
    "    # Plot the image with predicted label\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(f'Predicted Class: {class_label}')\n",
    "    ax.axis('off')\n",
    "    ax.text(10, 20, f'Prob:\\n{prob_distribution_str}', fontsize=20, ha='left', va='top', color='green')\n",
    "\n",
    "# List of image paths\n",
    "image_paths = ['./test_data/square.jpg', './test_data/heart.jpg', './test_data/long.jpg',\n",
    "               './test_data/round.jpg', './test_data/trangle.jpg']\n",
    "\n",
    "# Create subplots for each image\n",
    "fig, axes = plt.subplots(1, 5, figsize=(20, 6))\n",
    "\n",
    "# Iterate over each image path and plot\n",
    "for i, image_path in enumerate(image_paths):\n",
    "    predict_and_plot(image_path, model, axes[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
